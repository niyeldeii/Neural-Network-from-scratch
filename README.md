# Neural Network from Scratch

I am implementing  simple neural networks from scratch in Python 


## Description

This neural network is a basic implementation of a multi-layer perceptron (MLP) with a single hidden layer. It uses the **sigmoid** activation function and **mean squared error (MSE)** loss function to train the model. The training process involves using **gradient descent** to minimize the loss through backpropagation.

The project is designed to help understand the core workings of neural networks, from forward propagation to backpropagation and weight updates.

### Features:
- Feedforward and backpropagation algorithms
- Gradient descent for training
- Sigmoid activation function
- Mean squared error loss function

